{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING = True\n",
    "FOLDER_PATH_DATASET = \"/home/taiello/projects/glucose-prediction/data\"  # insert you dataset path\n",
    "FOLDER_PATH_ORIGINAL = f\"{FOLDER_PATH_DATASET}/original\"\n",
    "FOLDER_PATH_RAW = f\"{FOLDER_PATH_DATASET}/raw\"\n",
    "FOLDER_PATH_PATIENTS = f\"{FOLDER_PATH_RAW}/patients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    # Read the text file\n",
    "    bolus = pd.read_csv(f\"{FOLDER_PATH_ORIGINAL}/HDeviceBolus.txt\", sep=\"|\")\n",
    "    cgm = pd.read_csv(f\"{FOLDER_PATH_ORIGINAL}/HDeviceCGM.txt\", sep=\"|\")\n",
    "    wizard = pd.read_csv(f\"{FOLDER_PATH_ORIGINAL}/HDeviceWizard.txt\", sep=\"|\")\n",
    "    screening = pd.read_csv(f\"{FOLDER_PATH_ORIGINAL}/HScreening.txt\", sep=\"|\")\n",
    "\n",
    "    bolus_columns = [\"PtID\", \"SiteID\", \"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"Normal\"]\n",
    "    bolus = bolus[bolus_columns]\n",
    "    bolus.to_csv(f\"{FOLDER_PATH_RAW}/bolus.csv\", index=False)\n",
    "\n",
    "    cgm_columns = [\"PtID\", \"SiteID\", \"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"GlucoseValue\"]\n",
    "    cgm = cgm[cgm_columns]\n",
    "    cgm.to_csv(f\"{FOLDER_PATH_RAW}/cgm.csv\", index=False)\n",
    "\n",
    "    wizard.rename(columns={\"PtId\": \"PtID\"}, inplace=True)\n",
    "    wizard_columns = [\"PtID\", \"SiteID\", \"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"CarbInput\"]\n",
    "    # wizard = wizard[wizard_columns]\n",
    "    wizard.to_csv(f\"{FOLDER_PATH_RAW}/wizard.csv\", index=False)\n",
    "\n",
    "    screening.to_csv(f\"{FOLDER_PATH_RAW}/screening.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    cgm = pd.read_csv(f\"{FOLDER_PATH_RAW}/cgm.csv\")\n",
    "    cgm[\"time\"] = (\n",
    "        pd.to_datetime(\"2000-01-01\")\n",
    "        + pd.to_timedelta(cgm[\"DeviceDtTmDaysFromEnroll\"], unit=\"d\")\n",
    "        + pd.to_timedelta(cgm[\"DeviceTm\"])\n",
    "    )\n",
    "    cgm = cgm.drop(columns=[\"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"SiteID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    # compute the difference between two consecutive time for each patient\n",
    "    cgm[\"day\"] = cgm[\"time\"].dt.date\n",
    "    cgm.sort_values(by=[\"PtID\", \"time\"], inplace=True)\n",
    "    cgm[\"time_diff\"] = cgm.groupby([\"PtID\", \"day\"])[\"time\"].diff()\n",
    "    cgm[\"time_diff\"] = cgm[\"time_diff\"].dt.total_seconds() / 60\n",
    "    cgm[\"time_diff\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    max_time_diff_per_patient_per_day = cgm.groupby([\"PtID\", \"day\"])[\"time_diff\"].max()\n",
    "    cgm = cgm.merge(max_time_diff_per_patient_per_day, on=[\"PtID\", \"day\"], suffixes=(\"\", \"_max\"))\n",
    "    cgm = cgm[cgm[\"time_diff_max\"] < 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    # count the number of cgm per day\n",
    "    cgm_count = cgm.groupby([\"PtID\", \"day\"]).size().reset_index(name=\"count\")\n",
    "    cgm = cgm.merge(cgm_count, on=[\"PtID\", \"day\"], suffixes=(\"\", \"_count\"))\n",
    "    cgm = cgm[cgm[\"count\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    cgm.drop(columns=[\"time_diff\", \"day\", \"time_diff_max\", \"count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    wizard = pd.read_csv(f\"{FOLDER_PATH_RAW}/wizard.csv\")\n",
    "    wizard[\"time\"] = (\n",
    "        pd.to_datetime(\"2000-01-01\")\n",
    "        + pd.to_timedelta(wizard[\"DeviceDtTmDaysFromEnroll\"], unit=\"d\")\n",
    "        + pd.to_timedelta(wizard[\"DeviceTm\"])\n",
    "    )\n",
    "    wizard = wizard.drop(columns=[\"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"SiteID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    bolus = pd.read_csv(f\"{FOLDER_PATH_RAW}/bolus.csv\")\n",
    "    bolus[\"time\"] = (\n",
    "        pd.to_datetime(\"2000-01-01\")\n",
    "        + pd.to_timedelta(bolus[\"DeviceDtTmDaysFromEnroll\"], unit=\"d\")\n",
    "        + pd.to_timedelta(bolus[\"DeviceTm\"])\n",
    "    )\n",
    "    bolus = bolus.drop(columns=[\"DeviceDtTmDaysFromEnroll\", \"DeviceTm\", \"SiteID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    df = pd.concat([cgm, wizard, bolus], axis=0)\n",
    "    start_time = cgm[\"time\"].min()\n",
    "    end_time = cgm[\"time\"].max()\n",
    "    df = df[(df[\"time\"] >= start_time) & (df[\"time\"] <= end_time)]\n",
    "    df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    df_resampled = df.groupby(\"PtID\").resample(\"15min\").mean()\n",
    "    df_resampled.drop(columns=[\"PtID\"], inplace=True)\n",
    "    len(df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    # count the total GlucoseValue NaN\n",
    "    nan_glucose_pre = df_resampled[\"GlucoseValue\"].isna().sum()\n",
    "    print(f\"Number of NaN in GlucoseValue before filling: {nan_glucose_pre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate df_resampled['GlucoseValue'] with a linear interpolation\n",
    "if PREPROCESSING:\n",
    "    df_resampled[\"GlucoseValue\"] = df_resampled[\"GlucoseValue\"].interpolate(\n",
    "        method=\"linear\", limit_direction=\"both\", limit_area=\"inside\", limit=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    nan_glucose_post = df_resampled[\"GlucoseValue\"].isna().sum()\n",
    "    print(f\"Number of NaN in GlucoseValue after filling: {nan_glucose_post}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    # drop all rows with GlucoseValue missing\n",
    "    df_resampled.dropna(subset=[\"GlucoseValue\"], inplace=True)\n",
    "    df_resampled.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 0 to all missing values in the other columns\n",
    "if PREPROCESSING:\n",
    "    df_resampled.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    print(\"Total number of samples after resampling: \", len(df_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    df_resampled[\"day\"] = df_resampled[\"time\"].dt.date\n",
    "    df_resampled_count = df_resampled.groupby([\"PtID\", \"day\"]).size().reset_index(name=\"count_day\")\n",
    "    df_resampled = df_resampled.merge(df_resampled_count, on=[\"PtID\", \"day\"], suffixes=(\"\", \"_count_day\"))\n",
    "    df_resampled = df_resampled[df_resampled[\"count_day\"] >= 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    print(\"Total number of samples after removing the day inconplete: \", len(df_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count non zero values per day of Normal and CarbInput\n",
    "if PREPROCESSING:\n",
    "    df_resampled_count_normal = df_resampled.groupby([\"PtID\", \"day\"])[\"Normal\"].sum().reset_index(name=\"count_normal\")\n",
    "    df_resampled = df_resampled.merge(df_resampled_count_normal, on=[\"PtID\", \"day\"], suffixes=(\"\", \"_count_normal\"))\n",
    "    df_resampled = df_resampled[df_resampled[\"count_normal\"] > 0]\n",
    "    df_resampled_count_carb = df_resampled.groupby([\"PtID\", \"day\"])[\"CarbInput\"].sum().reset_index(name=\"count_carb\")\n",
    "    df_resampled = df_resampled.merge(df_resampled_count_carb, on=[\"PtID\", \"day\"], suffixes=(\"\", \"_count_carb\"))\n",
    "    df_resampled = df_resampled[df_resampled[\"count_carb\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    print(\"Total number of samples after removing the day inconplete: \", len(df_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    df_resampled.to_csv(f\"{FOLDER_PATH_RAW}/all.csv\", index=False)\n",
    "    for patient in df_resampled[\"PtID\"].unique():\n",
    "        patient_df = df_resampled[df_resampled[\"PtID\"] == patient]\n",
    "        patient_df.loc[\n",
    "            :, [\"time\", \"GlucoseValue\", \"Normal\", \"CarbInput\", \"count_day\", \"count_normal\", \"count_carb\"]\n",
    "        ].to_csv(f\"{FOLDER_PATH_PATIENTS}/{patient}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
